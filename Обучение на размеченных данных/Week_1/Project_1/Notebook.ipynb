{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 1 to 200\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   Radio      200 non-null    float64\n",
      " 2   Newspaper  200 non-null    float64\n",
      " 3   Sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 7.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([adver_data['TV'], adver_data['Radio'], adver_data['Newspaper']]) # Ваш код здесь\n",
    "X = X.T\n",
    "y = np.array(adver_data['Sales']) # Ваш код здесь\n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(X, axis=0)\n",
    "X = X - means\n",
    "stds = np.std(X, axis=0) # Ваш код здесь\n",
    "# print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X /stds # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[[ 1.00000000e+00  9.69852266e-01  9.81522472e-01  1.77894547e+00]\n",
      " [ 1.00000000e+00 -1.19737623e+00  1.08280781e+00  6.69578760e-01]\n",
      " [ 1.00000000e+00 -1.51615499e+00  1.52846331e+00  1.78354865e+00]\n",
      " [ 1.00000000e+00  5.20496822e-02  1.21785493e+00  1.28640506e+00]\n",
      " [ 1.00000000e+00  3.94182198e-01 -8.41613655e-01  1.28180188e+00]\n",
      " [ 1.00000000e+00 -1.61540845e+00  1.73103399e+00  2.04592999e+00]\n",
      " [ 1.00000000e+00 -1.04557682e+00  6.43904671e-01 -3.24708413e-01]\n",
      " [ 1.00000000e+00 -3.13436589e-01 -2.47406325e-01 -8.72486994e-01]\n",
      " [ 1.00000000e+00 -1.61657614e+00 -1.42906863e+00 -1.36042422e+00]\n",
      " [ 1.00000000e+00  6.16042873e-01 -1.39530685e+00 -4.30581584e-01]\n",
      " [ 1.00000000e+00 -9.45155670e-01 -1.17923146e+00 -2.92486143e-01]\n",
      " [ 1.00000000e+00  7.90028350e-01  4.96973404e-02 -1.22232878e+00]\n",
      " [ 1.00000000e+00 -1.43908760e+00  7.99208859e-01  1.62704048e+00]\n",
      " [ 1.00000000e+00 -5.78501712e-01 -1.05768905e+00 -1.07502697e+00]\n",
      " [ 1.00000000e+00  6.66253447e-01  6.50657027e-01  7.11007392e-01]\n",
      " [ 1.00000000e+00  5.64664612e-01  1.65000572e+00  1.02862691e+00]\n",
      " [ 1.00000000e+00 -9.25304978e-01  9.00494200e-01  3.84117072e+00]\n",
      " [ 1.00000000e+00  1.56887609e+00  1.10306488e+00  1.16211917e+00]\n",
      " [ 1.00000000e+00 -9.08957349e-01 -1.86635121e-01 -5.64073843e-01]\n",
      " [ 1.00000000e+00  3.00679600e-03  4.29449843e-02 -5.27248393e-01]\n",
      " [ 1.00000000e+00  8.33232798e-01  2.99534513e-01  1.05164281e+00]\n",
      " [ 1.00000000e+00  1.05509347e+00 -1.22649795e+00 -3.24708413e-01]\n",
      " [ 1.00000000e+00 -1.56286250e+00 -4.97243498e-01  8.76721921e-01]\n",
      " [ 1.00000000e+00  9.48833887e-01 -4.29719938e-01 -2.00422516e-01]\n",
      " [ 1.00000000e+00 -9.89527805e-01 -7.20071247e-01 -5.64073843e-01]\n",
      " [ 1.00000000e+00  1.35285385e+00 -1.33453565e+00 -5.08835667e-01]\n",
      " [ 1.00000000e+00 -4.83714657e-02  4.07572210e-01 -8.26455181e-01]\n",
      " [ 1.00000000e+00  1.08662104e+00 -4.43224650e-01 -3.52327501e-01]\n",
      " [ 1.00000000e+00  1.18820988e+00  2.59020377e-01 -3.52327501e-01]\n",
      " [ 1.00000000e+00 -8.92609721e-01 -4.90491142e-01  4.71641962e-01]\n",
      " [ 1.00000000e+00  1.70316018e+00  3.40048650e-01  5.82118314e-01]\n",
      " [ 1.00000000e+00 -3.98677796e-01 -3.95958157e-01  3.70371972e-01]\n",
      " [ 1.00000000e+00 -5.82004775e-01 -1.46958277e+00 -2.55016247e-02]\n",
      " [ 1.00000000e+00  1.38438142e+00 -2.20396901e-01 -1.39264649e+00]\n",
      " [ 1.00000000e+00 -5.99520091e-01 -1.47633512e+00 -1.06582061e+00]\n",
      " [ 1.00000000e+00  1.67747105e+00 -1.29402151e+00 -1.01518562e+00]\n",
      " [ 1.00000000e+00  1.39956136e+00  1.38666383e+00 -1.17629696e+00]\n",
      " [ 1.00000000e+00 -8.44734522e-01  1.76479577e+00  6.97197848e-01]\n",
      " [ 1.00000000e+00 -1.21372386e+00  2.32010953e-01  2.09260624e-01]\n",
      " [ 1.00000000e+00  9.45330823e-01  9.74770116e-01  6.65620024e-02]\n",
      " [ 1.00000000e+00  6.47570443e-01 -6.50927121e-02  4.81492770e-02]\n",
      " [ 1.00000000e+00  3.49810063e-01  6.84418807e-01  3.74975153e-01]\n",
      " [ 1.00000000e+00  1.71133400e+00  2.99534513e-01 -1.32359877e+00]\n",
      " [ 1.00000000e+00  6.98948705e-01 -1.00367020e+00 -1.91216154e-01]\n",
      " [ 1.00000000e+00 -1.42390765e+00  1.64487393e-01  5.86721496e-01]\n",
      " [ 1.00000000e+00  3.27623995e-01 -5.15880000e-02  4.35460956e-02]\n",
      " [ 1.00000000e+00 -6.69581357e-01 -9.02384859e-01  2.36879713e-01]\n",
      " [ 1.00000000e+00  1.08428567e+00  1.23135965e+00 -5.54867481e-01]\n",
      " [ 1.00000000e+00  9.35989321e-01 -5.03995854e-01  8.90531465e-01]\n",
      " [ 1.00000000e+00 -9.35814168e-01 -7.80842451e-01  2.87514708e-01]\n",
      " [ 1.00000000e+00  6.16042873e-01 -1.36154507e+00  1.86244718e-01]\n",
      " [ 1.00000000e+00 -5.44638766e-01 -9.22641928e-01 -1.24074150e+00]\n",
      " [ 1.00000000e+00  8.09879042e-01  1.24486436e+00  4.16403786e-01]\n",
      " [ 1.00000000e+00  4.15200577e-01  1.54872038e+00  1.29561142e+00]\n",
      " [ 1.00000000e+00  1.35051848e+00  3.73810430e-01 -6.74550196e-01]\n",
      " [ 1.00000000e+00  6.05533683e-01  1.76479577e+00  1.35545278e+00]\n",
      " [ 1.00000000e+00 -1.63175608e+00  3.26543937e-01  4.99261050e-01]\n",
      " [ 1.00000000e+00 -1.26606546e-01 -2.74415749e-01 -6.42327927e-01]\n",
      " [ 1.00000000e+00  7.44488528e-01  1.77830048e+00  3.28943340e-01]\n",
      " [ 1.00000000e+00  7.43320840e-01  4.21076922e-01 -9.78360166e-01]\n",
      " [ 1.00000000e+00 -1.09228433e+00 -1.43582099e+00 -4.21375221e-01]\n",
      " [ 1.00000000e+00  1.33417085e+00  1.31238792e+00  1.11148417e+00]\n",
      " [ 1.00000000e+00  1.07727954e+00 -5.24252922e-01 -1.49787521e-01]\n",
      " [ 1.00000000e+00 -5.17781948e-01  4.27829278e-01 -1.01978880e+00]\n",
      " [ 1.00000000e+00 -1.86158622e-01  1.31914027e+00 -7.61366196e-02]\n",
      " [ 1.00000000e+00 -9.11292725e-01 -9.42898996e-01 -1.36502740e+00]\n",
      " [ 1.00000000e+00 -1.34917564e+00  9.02114765e-02 -1.30518604e+00]\n",
      " [ 1.00000000e+00 -9.04082253e-02 -5.91776482e-01 -9.36931533e-01]\n",
      " [ 1.00000000e+00  1.05509347e+00  2.86029801e-01 -9.00106083e-01]\n",
      " [ 1.00000000e+00  8.14549794e-01  1.39341619e+00 -1.54390703e-01]\n",
      " [ 1.00000000e+00  6.07869059e-01  4.95352838e-01  3.74975153e-01]\n",
      " [ 1.00000000e+00 -4.34876116e-01 -6.05281194e-01  5.27524584e-02]\n",
      " [ 1.00000000e+00 -1.40405696e+00  6.57409383e-01 -5.18042030e-01]\n",
      " [ 1.00000000e+00 -2.06009314e-01 -1.18598381e+00  3.43397329e-02]\n",
      " [ 1.00000000e+00  7.74848409e-01  9.02114765e-02 -8.03439274e-01]\n",
      " [ 1.00000000e+00 -1.51965805e+00  1.37991148e+00  2.70878810e+00]\n",
      " [ 1.00000000e+00 -1.39588315e+00 -1.46283041e+00 -4.53597491e-01]\n",
      " [ 1.00000000e+00 -3.09933525e-01  3.53553362e-01 -7.52804279e-01]\n",
      " [ 1.00000000e+00 -1.65394214e+00  4.48086346e-01 -9.73756984e-01]\n",
      " [ 1.00000000e+00 -3.62479475e-01 -1.05093669e+00 -3.43121138e-01]\n",
      " [ 1.00000000e+00 -8.24883830e-01  2.32010953e-01 -3.79946589e-01]\n",
      " [ 1.00000000e+00  1.08311798e+00 -1.29402151e+00  2.92117889e-01]\n",
      " [ 1.00000000e+00 -8.37728396e-01 -2.00139833e-01  8.95779092e-02]\n",
      " [ 1.00000000e+00 -9.18298852e-01  1.43393033e+00  2.32276531e-01]\n",
      " [ 1.00000000e+00  7.76016097e-01  1.33264499e+00  1.49419267e-01]\n",
      " [ 1.00000000e+00  5.38975481e-01 -3.28434597e-01  1.61783412e+00]\n",
      " [ 1.00000000e+00 -8.26051518e-01  2.86029801e-01 -6.69947015e-01]\n",
      " [ 1.00000000e+00 -4.24366926e-01  1.17058844e+00  1.50275459e+00]\n",
      " [ 1.00000000e+00 -6.85928986e-01  1.50982681e-01  1.97227908e+00]\n",
      " [ 1.00000000e+00 -4.34876116e-01  1.65675807e+00  9.59579186e-01]\n",
      " [ 1.00000000e+00 -1.48792614e-01 -1.24000266e+00 -9.78360166e-01]\n",
      " [ 1.00000000e+00 -1.38303858e+00 -1.46958277e+00  1.12593816e-01]\n",
      " [ 1.00000000e+00  8.25058983e-01  6.91171163e-01  1.30942097e+00]\n",
      " [ 1.00000000e+00  1.21273132e+00  8.93741844e-01  1.92164409e+00]\n",
      " [ 1.00000000e+00 -4.62900623e-01 -6.25538262e-01 -9.04709264e-01]\n",
      " [ 1.00000000e+00  1.89836839e-01  5.62876398e-01  1.02862691e+00]\n",
      " [ 1.00000000e+00  5.90353742e-01 -1.33453565e+00 -1.13486833e+00]\n",
      " [ 1.00000000e+00  4.42057396e-01 -1.52873340e-01 -3.93756133e-01]\n",
      " [ 1.00000000e+00  1.66579418e+00  1.28537849e+00  9.50372823e-01]\n",
      " [ 1.00000000e+00 -1.38283424e-01  1.24486436e+00  7.06404211e-01]\n",
      " [ 1.00000000e+00  8.79940308e-01 -1.28051680e+00  8.85928284e-01]\n",
      " [ 1.00000000e+00  1.74402926e+00  8.80237132e-01  3.23815396e+00]\n",
      " [ 1.00000000e+00  1.55486384e+00 -8.88880147e-01 -4.21375221e-01]\n",
      " [ 1.00000000e+00  4.77088029e-01 -4.09462869e-01 -5.82486569e-01]\n",
      " [ 1.00000000e+00  1.06443498e+00  7.45190011e-01 -1.16248742e+00]\n",
      " [ 1.00000000e+00 -1.06755854e-01  1.56222509e+00  1.30942097e+00]\n",
      " [ 1.00000000e+00 -1.42507534e+00 -8.28108943e-01 -3.93111688e-02]\n",
      " [ 1.00000000e+00 -6.61407543e-01 -1.55061104e+00 -3.38517957e-01]\n",
      " [ 1.00000000e+00 -1.56403019e+00 -1.54385868e+00 -2.28041604e-01]\n",
      " [ 1.00000000e+00  1.26527727e+00  2.45515665e-01 -1.15328106e+00]\n",
      " [ 1.00000000e+00  9.19641692e-01 -1.01717491e+00  1.19434143e+00]\n",
      " [ 1.00000000e+00  1.10530405e+00  9.95027184e-01 -3.38517957e-01]\n",
      " [ 1.00000000e+00  3.34630122e-01 -5.31005278e-01 -1.29597968e+00]\n",
      " [ 1.00000000e+00  7.30476274e-01 -1.79882765e-01 -9.13915627e-01]\n",
      " [ 1.00000000e+00 -8.03865450e-01  1.58923451e+00  1.81641536e-01]\n",
      " [ 1.00000000e+00 -8.40063771e-01  7.92456503e-01  1.01942054e+00]\n",
      " [ 1.00000000e+00 -9.15759131e-02 -6.05281194e-01 -2.28041604e-01]\n",
      " [ 1.00000000e+00 -8.24883830e-01 -1.51684926e+00 -7.25185191e-01]\n",
      " [ 1.00000000e+00 -2.49213762e-01  9.20751268e-01  2.23926360e+00]\n",
      " [ 1.00000000e+00 -1.49046586e+00 -4.90491142e-01 -3.79946589e-01]\n",
      " [ 1.00000000e+00 -6.70544700e-02  2.38763309e-01  7.20213755e-01]\n",
      " [ 1.00000000e+00 -1.49747198e+00 -1.05606848e-01  9.13547372e-01]\n",
      " [ 1.00000000e+00  8.98623313e-01 -1.40881156e+00 -6.88359740e-01]\n",
      " [ 1.00000000e+00 -2.79573643e-01  7.65447079e-01 -8.35661544e-01]\n",
      " [ 1.00000000e+00  9.62846140e-01  6.10142891e-01  2.00910454e+00]\n",
      " [ 1.00000000e+00 -6.98773552e-01 -7.74090095e-01 -2.14232060e-01]\n",
      " [ 1.00000000e+00 -1.62591764e+00  1.05579839e+00  9.22753735e-01]\n",
      " [ 1.00000000e+00 -7.80511695e-01 -1.57086811e+00 -9.82963347e-01]\n",
      " [ 1.00000000e+00  8.55418865e-01  1.73778635e+00 -1.25915423e+00]\n",
      " [ 1.00000000e+00 -1.02105537e+00 -7.60585383e-01  5.77515133e-01]\n",
      " [ 1.00000000e+00 -1.70882347e+00  1.10306488e+00 -1.00597925e+00]\n",
      " [ 1.00000000e+00  1.37971067e+00 -1.37504978e+00  5.72911952e-01]\n",
      " [ 1.00000000e+00 -1.61891151e+00  2.65772733e-01 -1.30978922e+00]\n",
      " [ 1.00000000e+00  8.49580427e-01  6.91171163e-01  6.69578760e-01]\n",
      " [ 1.00000000e+00 -1.28612050e+00  1.03554132e+00  1.61323094e+00]\n",
      " [ 1.00000000e+00 -1.15300409e+00  1.60273923e+00 -1.01518562e+00]\n",
      " [ 1.00000000e+00 -1.41806922e+00  1.06255074e+00 -9.78360166e-01]\n",
      " [ 1.00000000e+00  1.47896413e+00  3.80562786e-01  1.34164324e+00]\n",
      " [ 1.00000000e+00 -1.21489154e+00  1.77992105e-01 -4.62803854e-01]\n",
      " [ 1.00000000e+00  4.42057396e-01  1.39341619e+00 -1.32820195e+00]\n",
      " [ 1.00000000e+00 -8.59914463e-01 -4.22967582e-01 -8.12645637e-01]\n",
      " [ 1.00000000e+00  5.44813920e-01  8.19465927e-01  2.07354907e+00]\n",
      " [ 1.00000000e+00  8.57754241e-01  6.70914095e-01  3.38149702e-01]\n",
      " [ 1.00000000e+00 -4.95595880e-01 -1.18598381e+00  1.77038355e-01]\n",
      " [ 1.00000000e+00 -5.93681653e-01 -5.71519414e-01  3.84181516e-01]\n",
      " [ 1.00000000e+00 -7.87313476e-02 -1.44257334e+00 -9.92169710e-01]\n",
      " [ 1.00000000e+00  1.08662104e+00 -1.07794612e+00 -1.00597925e+00]\n",
      " [ 1.00000000e+00  1.12281936e+00  1.73778635e+00  6.32753309e-01]\n",
      " [ 1.00000000e+00 -1.27327593e+00  1.15033137e+00 -8.58677450e-01]\n",
      " [ 1.00000000e+00 -1.19504085e+00  1.71239749e-01 -4.58200672e-01]\n",
      " [ 1.00000000e+00  1.56070228e+00 -6.32290618e-01  2.96721070e-01]\n",
      " [ 1.00000000e+00 -3.04095087e-01 -1.00367020e+00  8.35293289e-01]\n",
      " [ 1.00000000e+00  5.90353742e-01  2.43084817e-03 -7.52804279e-01]\n",
      " [ 1.00000000e+00  2.83251860e-01  1.10981724e+00  3.28943340e-01]\n",
      " [ 1.00000000e+00  4.75920341e-01 -1.46120984e-01 -9.69153803e-01]\n",
      " [ 1.00000000e+00 -1.66912209e+00 -7.87594807e-01 -1.14407469e+00]\n",
      " [ 1.00000000e+00 -6.20538471e-01  1.36640677e+00  9.18150553e-01]\n",
      " [ 1.00000000e+00  3.21989902e-02 -1.48308748e+00 -2.87882962e-01]\n",
      " [ 1.00000000e+00 -1.58037782e+00  9.20751268e-01  6.74181942e-01]\n",
      " [ 1.00000000e+00 -1.79152496e-01 -3.28434597e-01  1.86244718e-01]\n",
      " [ 1.00000000e+00  2.97264113e-01 -3.48691665e-01  6.72064478e-03]\n",
      " [ 1.00000000e+00 -7.16288868e-01  8.46475352e-01  8.62912377e-01]\n",
      " [ 1.00000000e+00  4.82926468e-01 -3.48691665e-01 -2.28041604e-01]\n",
      " [ 1.00000000e+00  1.92172214e-01  9.13998912e-01 -1.06582061e+00]\n",
      " [ 1.00000000e+00 -3.48467222e-01 -5.78271770e-01 -1.15788424e+00]\n",
      " [ 1.00000000e+00  1.02123053e+00 -1.34128800e+00  2.49704176e+00]\n",
      " [ 1.00000000e+00 -1.50798117e+00  9.68017760e-01 -4.12168859e-01]\n",
      " [ 1.00000000e+00  6.97781017e-01 -1.21974559e+00 -5.13438849e-01]\n",
      " [ 1.00000000e+00  7.98202165e-01  2.26879163e-02  1.24497643e+00]\n",
      " [ 1.00000000e+00  1.60273904e+00 -8.55118367e-01 -1.11185242e+00]\n",
      " [ 1.00000000e+00 -1.13315340e+00 -7.87594807e-01 -5.59470662e-01]\n",
      " [ 1.00000000e+00  2.03849092e-01 -1.59625696e-01  7.75451931e-01]\n",
      " [ 1.00000000e+00 -1.48813048e+00 -2.13644545e-01 -6.23915201e-01]\n",
      " [ 1.00000000e+00  2.49388915e-01 -1.09145083e+00 -8.17248818e-01]\n",
      " [ 1.00000000e+00  8.79940308e-01 -1.34128800e+00 -8.03439274e-01]\n",
      " [ 1.00000000e+00  1.51633014e+00  1.73103399e+00  5.17673775e-01]\n",
      " [ 1.00000000e+00  1.18353913e+00  4.68343414e-01 -4.72010216e-01]\n",
      " [ 1.00000000e+00  2.70407294e-01 -1.04418434e+00  2.13863806e-01]\n",
      " [ 1.00000000e+00  1.51399477e+00 -1.41556392e+00 -3.15502050e-01]\n",
      " [ 1.00000000e+00  2.16693657e-01 -8.95632503e-01 -5.96296113e-01]\n",
      " [ 1.00000000e+00  1.11601758e-01 -1.39530685e+00 -1.02439198e+00]\n",
      " [ 1.00000000e+00  8.34400486e-01 -1.20624088e+00 -1.45184340e-01]\n",
      " [ 1.00000000e+00 -1.06075676e+00 -1.18598381e+00 -3.93111688e-02]\n",
      " [ 1.00000000e+00  1.64127273e+00  1.33264499e+00  1.89862818e+00]\n",
      " [ 1.00000000e+00  1.24659427e+00 -1.32616272e-01 -2.55016247e-02]\n",
      " [ 1.00000000e+00  6.76762637e-01  1.47444446e+00 -5.04232486e-01]\n",
      " [ 1.00000000e+00 -8.80728498e-02 -1.42906863e+00 -1.82009791e-01]\n",
      " [ 1.00000000e+00  5.14454038e-01  3.67058074e-01 -5.68677025e-01]\n",
      " [ 1.00000000e+00  1.62258973e+00 -6.32290618e-01 -1.23613832e+00]\n",
      " [ 1.00000000e+00 -1.49863967e+00 -7.53833027e-01 -3.29311594e-01]\n",
      " [ 1.00000000e+00 -1.25576062e+00  1.20435022e+00 -1.13947151e+00]\n",
      " [ 1.00000000e+00 -8.35393020e-01 -8.41613655e-01 -1.13026515e+00]\n",
      " [ 1.00000000e+00 -1.51615499e+00 -1.29402151e+00  4.81492770e-02]\n",
      " [ 1.00000000e+00  2.30705910e-01  1.26512143e+00 -1.24074150e+00]\n",
      " [ 1.00000000e+00  3.10313024e-02  8.32970639e-01 -1.13026515e+00]\n",
      " [ 1.00000000e+00 -1.27094056e+00 -1.32103093e+00 -7.71217005e-01]\n",
      " [ 1.00000000e+00 -6.17035408e-01 -1.24000266e+00 -1.03359834e+00]\n",
      " [ 1.00000000e+00  3.49810063e-01 -9.42898996e-01 -1.11185242e+00]\n",
      " [ 1.00000000e+00  1.59456522e+00  1.26512143e+00  1.64085003e+00]\n",
      " [ 1.00000000e+00  9.93206022e-01 -9.90165488e-01 -1.00597925e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N = X.shape[0]\n",
    "print(N)\n",
    "one = np.ones((N,1))\n",
    "X = np.hstack((one, X)) # Ваш код здесь\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.mean((y - y_pred)**2) # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "med = np.median(np.array(adver_data['Sales']))\n",
    "y_pred = np.ones((N))*med\n",
    "y = np.array(adver_data['Sales'])\n",
    "# print(y_pred, y)\n",
    "answer1 =  mserror(y, y_pred)\n",
    "print(round(answer1, 3))\n",
    "# answer1 = 28.34575"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    X_t = X.transpose()\n",
    "    X_obr = np.dot(X_t, X)\n",
    "    X_obr = np.linalg.inv(X_obr)\n",
    "    Sol = np.dot(X_obr, X_t)\n",
    "    return np.dot(Sol,y)  # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0225      3.91925365  2.79206274 -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)\n",
    "# [ 3.91925365  2.79206274 -0.02253861 14.0225    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.022\n"
     ]
    }
   ],
   "source": [
    "X_0 = np.array([1, 0, 0, 0])\n",
    "answer2 = np.dot(X_0,norm_eq_weights) # Ваш код здесь\n",
    "print(np.round(answer2, 3))\n",
    "\n",
    "# 14.022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w) # Ваш код здесь\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_prediction(X, norm_eq_weights)\n",
    "y = np.array(adver_data['Sales'])\n",
    "\n",
    "answer3 = mserror(y, y_pred) # Ваш код здесь\n",
    "print(round(answer3, 3))\n",
    "\n",
    "# 2.784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.414     ,  0.70849228,  0.12400729, -0.54796989])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    res = X[train_ind][0]*w[0] + X[train_ind][1]*w[1] + X[train_ind][2]*w[2] + X[train_ind][3]*w[3]\n",
    "    grad0 = 2 * ( res - y[train_ind] ) * X[train_ind][0] # Ваш код здесь\n",
    "    grad1 = 2 * ( res - y[train_ind] ) * X[train_ind][1] # Ваш код здесь\n",
    "    grad2 = 2 * ( res - y[train_ind] ) * X[train_ind][2] # Ваш код здесь\n",
    "    grad3 = 2 * ( res - y[train_ind] ) * X[train_ind][3] # Ваш код здесь\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])\n",
    "\n",
    "\n",
    "stochastic_gradient_step(X, y, w = [0, 0, 0, 0], train_ind=42, eta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.96985227 0.98152247 1.77894547]\n",
      "iter_num =  100\n",
      "\tweight_dist =  0.022912199555945343\n",
      "\terror =  8.341872748055305\n",
      "\trandom_ind =  156\n",
      "iter_num =  200\n",
      "\tweight_dist =  0.1295892170235495\n",
      "\terror =  3.1291378146955107\n",
      "\trandom_ind =  117\n",
      "iter_num =  300\n",
      "\tweight_dist =  0.01269678212073271\n",
      "\terror =  3.122912866460378\n",
      "\trandom_ind =  115\n",
      "iter_num =  400\n",
      "\tweight_dist =  0.06991771055100945\n",
      "\terror =  2.851331467580323\n",
      "\trandom_ind =  129\n",
      "iter_num =  500\n",
      "\tweight_dist =  0.0647404250142862\n",
      "\terror =  2.888207224537173\n",
      "\trandom_ind =  15\n",
      "iter_num =  600\n",
      "\tweight_dist =  0.05171145474672004\n",
      "\terror =  3.0808593539241813\n",
      "\trandom_ind =  151\n",
      "iter_num =  700\n",
      "\tweight_dist =  0.013852016732592419\n",
      "\terror =  2.918536376278194\n",
      "\trandom_ind =  172\n",
      "iter_num =  800\n",
      "\tweight_dist =  0.0038147237559221724\n",
      "\terror =  2.917684018558395\n",
      "\trandom_ind =  85\n",
      "iter_num =  900\n",
      "\tweight_dist =  0.031946879592385194\n",
      "\terror =  2.9181906203012886\n",
      "\trandom_ind =  94\n",
      "iter_num =  1000\n",
      "\tweight_dist =  0.023814830644700847\n",
      "\terror =  2.987636139335741\n",
      "\trandom_ind =  7\n",
      "iter_num =  1100\n",
      "\tweight_dist =  0.03235007206154665\n",
      "\terror =  2.8215118130085646\n",
      "\trandom_ind =  37\n",
      "iter_num =  1200\n",
      "\tweight_dist =  0.21774504649598794\n",
      "\terror =  3.021907851204132\n",
      "\trandom_ind =  183\n",
      "iter_num =  1300\n",
      "\tweight_dist =  0.05827541676957232\n",
      "\terror =  2.866387807133019\n",
      "\trandom_ind =  151\n",
      "iter_num =  1400\n",
      "\tweight_dist =  0.03697853849310671\n",
      "\terror =  2.8647092457060874\n",
      "\trandom_ind =  73\n",
      "iter_num =  1500\n",
      "\tweight_dist =  0.011794934963014583\n",
      "\terror =  3.1264576798530412\n",
      "\trandom_ind =  28\n",
      "iter_num =  1600\n",
      "\tweight_dist =  0.06015197303682198\n",
      "\terror =  2.810300202307295\n",
      "\trandom_ind =  151\n",
      "iter_num =  1700\n",
      "\tweight_dist =  0.02796665696110914\n",
      "\terror =  2.961915275695068\n",
      "\trandom_ind =  168\n",
      "iter_num =  1800\n",
      "\tweight_dist =  0.010576272118729156\n",
      "\terror =  2.88296087411084\n",
      "\trandom_ind =  57\n",
      "iter_num =  1900\n",
      "\tweight_dist =  0.06054002764799111\n",
      "\terror =  2.9297709782936\n",
      "\trandom_ind =  83\n",
      "iter_num =  2000\n",
      "\tweight_dist =  0.0315269828555971\n",
      "\terror =  2.8577685088799263\n",
      "\trandom_ind =  153\n",
      "iter_num =  2100\n",
      "\tweight_dist =  0.06921709131600912\n",
      "\terror =  2.940875301182045\n",
      "\trandom_ind =  49\n",
      "iter_num =  2200\n",
      "\tweight_dist =  0.0727339645601511\n",
      "\terror =  2.8492814250454965\n",
      "\trandom_ind =  129\n",
      "iter_num =  2300\n",
      "\tweight_dist =  0.025479540689724807\n",
      "\terror =  2.829952122291937\n",
      "\trandom_ind =  82\n",
      "iter_num =  2400\n",
      "\tweight_dist =  0.16454800192985206\n",
      "\terror =  2.8620552625688744\n",
      "\trandom_ind =  158\n",
      "iter_num =  2500\n",
      "\tweight_dist =  0.07001026307844818\n",
      "\terror =  2.9984974435529295\n",
      "\trandom_ind =  135\n",
      "iter_num =  2600\n",
      "\tweight_dist =  0.0024093749825640086\n",
      "\terror =  3.1170735358683612\n",
      "\trandom_ind =  85\n",
      "iter_num =  2700\n",
      "\tweight_dist =  0.1390395903395023\n",
      "\terror =  2.98859715506355\n",
      "\trandom_ind =  102\n",
      "iter_num =  2800\n",
      "\tweight_dist =  0.014692527029124124\n",
      "\terror =  2.871782875523636\n",
      "\trandom_ind =  42\n",
      "iter_num =  2900\n",
      "\tweight_dist =  0.0787893806920449\n",
      "\terror =  2.851536579049001\n",
      "\trandom_ind =  150\n",
      "iter_num =  3000\n",
      "\tweight_dist =  0.014364539639757716\n",
      "\terror =  2.864204578414158\n",
      "\trandom_ind =  70\n",
      "iter_num =  3100\n",
      "\tweight_dist =  0.0455884624132288\n",
      "\terror =  2.883302860481318\n",
      "\trandom_ind =  69\n",
      "iter_num =  3200\n",
      "\tweight_dist =  0.048778078160252904\n",
      "\terror =  2.856049821520777\n",
      "\trandom_ind =  64\n",
      "iter_num =  3300\n",
      "\tweight_dist =  0.18147674464448627\n",
      "\terror =  3.3562247218890833\n",
      "\trandom_ind =  128\n",
      "iter_num =  3400\n",
      "\tweight_dist =  0.0338182264491092\n",
      "\terror =  3.095681234578022\n",
      "\trandom_ind =  86\n",
      "iter_num =  3500\n",
      "\tweight_dist =  0.012581311793137267\n",
      "\terror =  2.871205706726524\n",
      "\trandom_ind =  157\n",
      "iter_num =  3600\n",
      "\tweight_dist =  0.06486724722900021\n",
      "\terror =  2.7991417406833783\n",
      "\trandom_ind =  61\n",
      "iter_num =  3700\n",
      "\tweight_dist =  0.008655330146737486\n",
      "\terror =  3.2451356352416236\n",
      "\trandom_ind =  168\n",
      "iter_num =  3800\n",
      "\tweight_dist =  0.05810273068043367\n",
      "\terror =  2.82207624815984\n",
      "\trandom_ind =  50\n",
      "iter_num =  3900\n",
      "\tweight_dist =  0.07929674722071708\n",
      "\terror =  2.8524369067595243\n",
      "\trandom_ind =  146\n",
      "iter_num =  4000\n",
      "\tweight_dist =  0.00013943109573652808\n",
      "\terror =  2.810381683547172\n",
      "\trandom_ind =  157\n",
      "iter_num =  4100\n",
      "\tweight_dist =  0.04078839444643286\n",
      "\terror =  2.9283847329979937\n",
      "\trandom_ind =  7\n",
      "iter_num =  4200\n",
      "\tweight_dist =  0.00142696440641979\n",
      "\terror =  2.8962680714555695\n",
      "\trandom_ind =  99\n",
      "iter_num =  4300\n",
      "\tweight_dist =  0.07145256908868923\n",
      "\terror =  3.3196410615428773\n",
      "\trandom_ind =  21\n",
      "iter_num =  4400\n",
      "\tweight_dist =  0.03224591522035004\n",
      "\terror =  2.9191259181771487\n",
      "\trandom_ind =  79\n",
      "iter_num =  4500\n",
      "\tweight_dist =  0.33013380721142266\n",
      "\terror =  2.9252212719446833\n",
      "\trandom_ind =  75\n",
      "iter_num =  4600\n",
      "\tweight_dist =  0.0825043890395552\n",
      "\terror =  3.1554426744563386\n",
      "\trandom_ind =  53\n",
      "iter_num =  4700\n",
      "\tweight_dist =  0.09099218693593901\n",
      "\terror =  3.042828562390139\n",
      "\trandom_ind =  146\n",
      "iter_num =  4800\n",
      "\tweight_dist =  0.10000385696968049\n",
      "\terror =  3.077391987389577\n",
      "\trandom_ind =  21\n",
      "iter_num =  4900\n",
      "\tweight_dist =  0.0218984077967679\n",
      "\terror =  2.966113355632125\n",
      "\trandom_ind =  112\n",
      "iter_num =  5000\n",
      "\tweight_dist =  0.03718177136364276\n",
      "\terror =  2.8101429648534064\n",
      "\trandom_ind =  83\n",
      "iter_num =  5100\n",
      "\tweight_dist =  0.01863911177294469\n",
      "\terror =  3.026418825160265\n",
      "\trandom_ind =  73\n",
      "iter_num =  5200\n",
      "\tweight_dist =  0.057252895486733686\n",
      "\terror =  3.117625206835348\n",
      "\trandom_ind =  181\n",
      "iter_num =  5300\n",
      "\tweight_dist =  0.020258437269079083\n",
      "\terror =  2.8925474286692032\n",
      "\trandom_ind =  134\n",
      "iter_num =  5400\n",
      "\tweight_dist =  0.05318098792881073\n",
      "\terror =  3.30497674912598\n",
      "\trandom_ind =  47\n",
      "iter_num =  5500\n",
      "\tweight_dist =  0.09379141216417322\n",
      "\terror =  2.9146896546655476\n",
      "\trandom_ind =  175\n",
      "iter_num =  5600\n",
      "\tweight_dist =  0.08557443662482189\n",
      "\terror =  2.8028811816801005\n",
      "\trandom_ind =  182\n",
      "iter_num =  5700\n",
      "\tweight_dist =  0.01778080974260639\n",
      "\terror =  3.270838960572112\n",
      "\trandom_ind =  19\n",
      "iter_num =  5800\n",
      "\tweight_dist =  0.002539372749652727\n",
      "\terror =  2.801812369147695\n",
      "\trandom_ind =  103\n",
      "iter_num =  5900\n",
      "\tweight_dist =  0.015552576018655465\n",
      "\terror =  2.9086608015544813\n",
      "\trandom_ind =  179\n",
      "iter_num =  6000\n",
      "\tweight_dist =  0.055937612578006383\n",
      "\terror =  3.0179912970569536\n",
      "\trandom_ind =  71\n",
      "iter_num =  6100\n",
      "\tweight_dist =  0.030029888502525623\n",
      "\terror =  2.9639701783021883\n",
      "\trandom_ind =  170\n",
      "iter_num =  6200\n",
      "\tweight_dist =  0.05789800048982641\n",
      "\terror =  3.3152145561412465\n",
      "\trandom_ind =  184\n",
      "iter_num =  6300\n",
      "\tweight_dist =  0.06994770172676562\n",
      "\terror =  2.927961327033559\n",
      "\trandom_ind =  81\n",
      "iter_num =  6400\n",
      "\tweight_dist =  0.09785112396236229\n",
      "\terror =  3.209881545866558\n",
      "\trandom_ind =  117\n",
      "iter_num =  6500\n",
      "\tweight_dist =  0.02997258278553125\n",
      "\terror =  2.8622797052690463\n",
      "\trandom_ind =  43\n",
      "iter_num =  6600\n",
      "\tweight_dist =  0.08797497809413511\n",
      "\terror =  2.8695629110602487\n",
      "\trandom_ind =  136\n",
      "iter_num =  6700\n",
      "\tweight_dist =  0.002037231586317029\n",
      "\terror =  3.0233190850499376\n",
      "\trandom_ind =  80\n",
      "iter_num =  6800\n",
      "\tweight_dist =  0.07541123816165803\n",
      "\terror =  2.7915328179423726\n",
      "\trandom_ind =  17\n",
      "iter_num =  6900\n",
      "\tweight_dist =  0.05953767993778796\n",
      "\terror =  2.830035897912813\n",
      "\trandom_ind =  199\n",
      "iter_num =  7000\n",
      "\tweight_dist =  0.09043681930299244\n",
      "\terror =  3.0574457549972918\n",
      "\trandom_ind =  76\n",
      "iter_num =  7100\n",
      "\tweight_dist =  0.055710443531539144\n",
      "\terror =  2.90828330323453\n",
      "\trandom_ind =  88\n",
      "iter_num =  7200\n",
      "\tweight_dist =  0.007162286060111014\n",
      "\terror =  2.986416308090686\n",
      "\trandom_ind =  19\n",
      "iter_num =  7300\n",
      "\tweight_dist =  0.05634089218432963\n",
      "\terror =  2.9654465215837513\n",
      "\trandom_ind =  122\n",
      "iter_num =  7400\n",
      "\tweight_dist =  0.1589618897230374\n",
      "\terror =  2.8760938893896424\n",
      "\trandom_ind =  131\n",
      "iter_num =  7500\n",
      "\tweight_dist =  0.01003310715474181\n",
      "\terror =  2.9992376264721075\n",
      "\trandom_ind =  19\n",
      "iter_num =  7600\n",
      "\tweight_dist =  0.004337991455671414\n",
      "\terror =  2.993943479361799\n",
      "\trandom_ind =  197\n",
      "iter_num =  7700\n",
      "\tweight_dist =  0.0003427614094475788\n",
      "\terror =  2.8926593189111536\n",
      "\trandom_ind =  172\n",
      "iter_num =  7800\n",
      "\tweight_dist =  0.07981526056662124\n",
      "\terror =  2.8126132789187444\n",
      "\trandom_ind =  185\n",
      "iter_num =  7900\n",
      "\tweight_dist =  0.011363311581170304\n",
      "\terror =  3.650187839195935\n",
      "\trandom_ind =  197\n",
      "iter_num =  8000\n",
      "\tweight_dist =  0.051723304124640976\n",
      "\terror =  2.896044228822461\n",
      "\trandom_ind =  148\n",
      "iter_num =  8100\n",
      "\tweight_dist =  0.04386528524471444\n",
      "\terror =  2.9484622622835572\n",
      "\trandom_ind =  87\n",
      "iter_num =  8200\n",
      "\tweight_dist =  0.03886858952246635\n",
      "\terror =  3.4340259259388084\n",
      "\trandom_ind =  24\n",
      "iter_num =  8300\n",
      "\tweight_dist =  0.0013743684446903693\n",
      "\terror =  2.9228925579912466\n",
      "\trandom_ind =  163\n",
      "iter_num =  8400\n",
      "\tweight_dist =  0.09721048899790234\n",
      "\terror =  2.8621082184306954\n",
      "\trandom_ind =  182\n",
      "iter_num =  8500\n",
      "\tweight_dist =  0.07438454882168005\n",
      "\terror =  2.8162486894735164\n",
      "\trandom_ind =  199\n",
      "iter_num =  8600\n",
      "\tweight_dist =  0.010786145582090147\n",
      "\terror =  2.9457876156817715\n",
      "\trandom_ind =  45\n",
      "iter_num =  8700\n",
      "\tweight_dist =  0.012596296280945166\n",
      "\terror =  2.920225653443224\n",
      "\trandom_ind =  63\n",
      "iter_num =  8800\n",
      "\tweight_dist =  0.010314843791090957\n",
      "\terror =  2.8352068454014234\n",
      "\trandom_ind =  113\n",
      "iter_num =  8900\n",
      "\tweight_dist =  0.06186140891277161\n",
      "\terror =  2.8284661353964795\n",
      "\trandom_ind =  72\n",
      "iter_num =  9000\n",
      "\tweight_dist =  0.008130394595588383\n",
      "\terror =  2.877740850031375\n",
      "\trandom_ind =  68\n",
      "iter_num =  9100\n",
      "\tweight_dist =  0.04220340405674384\n",
      "\terror =  3.1080359086356055\n",
      "\trandom_ind =  63\n",
      "iter_num =  9200\n",
      "\tweight_dist =  0.01757838305143563\n",
      "\terror =  2.8154109052969227\n",
      "\trandom_ind =  186\n",
      "iter_num =  9300\n",
      "\tweight_dist =  0.09861961084478792\n",
      "\terror =  2.8609997974550994\n",
      "\trandom_ind =  182\n",
      "iter_num =  9400\n",
      "\tweight_dist =  0.005418297776589339\n",
      "\terror =  3.100950166374416\n",
      "\trandom_ind =  68\n",
      "iter_num =  9500\n",
      "\tweight_dist =  0.07309530750011295\n",
      "\terror =  2.872697798623165\n",
      "\trandom_ind =  196\n",
      "iter_num =  9600\n",
      "\tweight_dist =  0.09789322193650057\n",
      "\terror =  2.8936543415376184\n",
      "\trandom_ind =  108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_num =  9700\n",
      "\tweight_dist =  0.03308112572423402\n",
      "\terror =  2.810282081942034\n",
      "\trandom_ind =  96\n",
      "iter_num =  9800\n",
      "\tweight_dist =  0.1225461048473958\n",
      "\terror =  2.9860758440325315\n",
      "\trandom_ind =  198\n",
      "iter_num =  9900\n",
      "\tweight_dist =  0.07710208716831274\n",
      "\terror =  2.815673904490816\n",
      "\trandom_ind =  33\n",
      "iter_num =  10000\n",
      "\tweight_dist =  0.02944278090296643\n",
      "\terror =  2.89479600457249\n",
      "\trandom_ind =  111\n",
      "w =  [14.18840901  3.63310309  2.84644722 -0.0299736 ]\n",
      "errors[0] =  213.9297943380191\n",
      "errors[-1] =  2.89479600457249\n",
      "mean.errors[-1] =  3.5251871368852328\n"
     ]
    }
   ],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        # Ваш код здесь\n",
    "        w_new=stochastic_gradient_step(X=X, y=y, w=w, train_ind=random_ind, eta=eta)\n",
    "        weight_dist = (sum((w - w_new)**2))**0.5\n",
    "        y_pred = linear_prediction(X, w_new)\n",
    "        error = mserror(y, y_pred)\n",
    "        errors.append(error)\n",
    "        w = w_new\n",
    "        iter_num += 1\n",
    "        if (iter_num % 100) == 0 and verbose == True:\n",
    "            print('iter_num = ', iter_num)\n",
    "            print('\\tweight_dist = ', weight_dist)\n",
    "            print('\\terror = ', error)\n",
    "            print('\\trandom_ind = ', random_ind)\n",
    "    if verbose == True:\n",
    "        print('w = ', w)\n",
    "        print('errors[0] = ', errors[0])\n",
    "        print('errors[-1] = ', errors[-1])\n",
    "        print('mean.errors[-1] = ', np.mean(errors))\n",
    "    return w, errors\n",
    "\n",
    "w_init = np.array([0, 0, 0, 0])\n",
    "y = np.array(adver_data['Sales'])\n",
    "print(X[0]) # [0.96985227 0.98152247 1.77894547 1.]\n",
    "w, errors =stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4, min_weight_dist=1e-8, \n",
    "                            seed=42, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 440 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.89479600457249"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w_init = np.array([0, 0, 0, 0])\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, w_init, eta=0.01, max_iter=1e4, min_weight_dist=1e-8, \n",
    "                            seed=42, verbose=False)# Ваш код здесь\n",
    "\n",
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.18840901,  3.63310309,  2.84644722, -0.0299736 ])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.89479600457249"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.895\n"
     ]
    }
   ],
   "source": [
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False)\n",
    "\n",
    "y_pred = linear_prediction(X, stoch_grad_desc_weights)\n",
    "y = np.array(adver_data['Sales'])\n",
    "answer4 =  mserror(y, y_pred) # Ваш код здесь\n",
    "# answer4 =  stoch_errors_by_iter[-1]\n",
    "print(round(answer4, 3))\n",
    "# 2.856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 16,  4], dtype=int32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "a_new = np.array([3, 6, 1])\n",
    "\n",
    "((a - a_new)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
